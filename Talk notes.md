# Talk notes
Title-0 How Can Voice Output Phonemes be used in Assistive Technology?

Andrea Lee, Will Wade, Kirsty McNaught and Heather Graz Will Wade have come together through a
shared exploration of the clinical applications of speech synthesis using phonemic input. To date,
speech synthesisers have used text, either from keyboard input or from text attached to symbol
messages, as the source to be converted to speech. Recent advances have meant that phonemes
can now be blended synthetically to form intelligible connected speech.
Andrea Lee is exploring how symbolised phonemes can be used communicatively as an addition or
alternative to the current AAC packages which use symbolised words and messages. An individual’s
vocabulary choices are integral to their social, cultural and linguistic identity. The use of standardised
symbol vocabularies based on frequency of word use or perceived importance of vocabulary does
not support individualised vocabulary needs. Users of symbolised word-based systems are restricted
to retrieving pre-stored, pre-empted vocabulary. Andrea Lee’s research explores how using
symbolised phonemes might impact the vocabulary choices of users.
Kirsty McNaught and Heather Graz haveas been working with voice output phonemes to support
literacy for an adult AAC user with literacy difficulties persisting into adulthood. Access to
symbolized phonemes enabled the user to create an intelligible version of words she was unable to
spell. The errors that may have been made in the phoneme selection wereas found to be less
harmful that alphabetic errors. The ongoing use of symbolised phonemes to support generalisation
to conventional spelling skill is currently being trialled.
Will Wade’s research specialism is efficiency and rate enhancement of AAC for those using text to
speech. This has two strands relating to phoneme use; firstly the use of alternative coding systems
such as the IPA (International Phonetic Alphabet) to reduce the number of keystrokes and
consequently increase efficiency and secondly, the learnability and gamification of coding systems
which result in improved engagement and adoption.
The session will involve demonstrations of prototypes and video examples of clinical use of the
methods presented.

## Original random thoughts
- Will and Andrea have done symbolised phonemes in MindExpress (AAC app) and in their own web demo
- Kirsty and Heather have similar in their Optikey based app
- ther's an equality/diversity side to this - AAC users wneed to be free to present whatever social/cultural voice they want, including e.g. dialects that aren't represented by their standard vocab. 
- Andrea will show some videos and talk through the website.
- Symbolised phonemes are intended as ADDITION to AAC
- Will's angle - it's a great idea. symbol based vocab is a bit of a scam. Child development re understanding phonemse etc doesn't map to symbolised communication. Why aren't we followign mainstream processes
- symbols were originally supposed to represnet concepts but over time have been bastardised into whole words
- This solves multilingual issues etc
- lots of ppl across the world aren't fully literate but just transliterate from spoken language e.g. pashto languages. 
- also compare to chinese transliteration systems - people combine approx sounds and system predicts written words
- they want to demo their web tools - personalising speech sounds, gamify, staggered learning, etc. 
- Open the conversation 
- Encourage ppl to go and use it
- Literacy development
- There's stuff to be said about efficiency compared to symbol vocab
- Kirsty has QWERTY layout - can be useful for people already familiar, but theres some ambiguity and it makes you need to be aware of whether you're writing in graphemes or phonemes. e.g. something that starts with 'g' but sounds like 'j' 
- Andrea has made some personalised ones that keep some letters to represent phonemes, but with very personalised choice of e.g. whether to use a capital or a lower case to imply different sounds
- Personalisation is really key
- Will's worry is that is looks like 'just another phoneme keyboard' - but all the blending etc is novel
- this is a useful tool for literacy 
- this is not a literacy "method". It's not the Initial Teaching alphabet
- intended to supplement and support literacy learning / speech therapy
- this is crucial for filling the gap of needing to communicate a word that you don't have in your vocab (and, for literate users, can't spell)
- Speech therapy focuses on phonological awareness. Non speaking children miss this
- gives users a way to create sounds and blend them 
- Heather says the phonological loop is still there in non speaking children, but the internal representation may be fuzzier
- Kirsty and Will will discuss what's feasible for a tech demo in the workshop
- Andrea's started playing wiht word games etc
- These tools let you do word games like rhyming, making up words, etc - that non speaking children otherwise miss out on, or e.g. a rhyming game from a symbol pageset is silly, the groupings are not at all sound based
- We learn from mistakes - you can't make sound/literacy based mistakes with a symbol pageset, but a way to blend phonemes lets you try and learn from mistakes
- we might need to acknowledge we have a bunch of adults with messed up literacy, and don't know what the new generation will get
- everyone's pathway to communication and/or literacy is different
- could look at stats on symbol vocab 
- Kirsty / Heather work focused on 2 aspects: filling a gap (what do you do when you can't say a word) and supporting literacy development (Heather can say more)
- could do a fun web demo e.g. name this monster? could also tie into 'kiki' vs 'booboo' effect
- useful for: literacy, communication, social participation
- there will always be some people who are never going to be fully literate or will always have residual literacy problems - where do they fit in
- most existing users struggle most with vowels



The game I had started was more of a pairs/matching/sound lotto type game with a visual scene to learn the image +sound matches – but maybe they don’t need that and they just learn through trial and play. The lady who will try it for me loves her garden so I was basing it on a flowery garden (bluebell, poppy, tulip, sunflower, lily) with a mouse moving around it for an /ee/ sound to see if she can do minimal pairs

Bluebell + mouse = bee

tulip + mouse = tea

sunflower + mouse = sea/see

poppy + mouse = pea/pee

lily +mouse = Lee

 

Heather – I feel like I’m naturally veering towards replicating Nuffield, Metaphon, cued articulation type teaching tools which I think makes sense as I feel like it is teaching them about speech sounds as building blocks rather than going straight in at semantic level. 